# MCP Server Configuration
MCP_SERVER_PORT=8000

# OpenAI API (optional - for embeddings/LLM)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API (optional - for Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Vector Store Configuration
VECTOR_STORE_TYPE=chromadb
CHROMA_DB_PATH=./data/chroma_db

# Embedding Model (local models don't require API keys)
EMBEDDING_MODEL=all-MiniLM-L6-v2
# EMBEDDING_MODEL=text-embedding-3-small

# Document Storage
DOCUMENT_STORAGE_PATH=./data/documents

# LLM Configuration (for answer generation)
USE_LLM=false
LLM_MODEL_NAME=mistralai/Mistral-7B-Instruct-v0.2
# LLM_MODEL_NAME=meta-llama/Llama-2-7b-chat-hf
# LLM_MODEL_NAME=distilgpt2  # For testing (smaller, faster)
